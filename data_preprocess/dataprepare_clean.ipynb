{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import subprocess, shlex\n",
    "import random\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download video from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "with open(\"invalidpatch.csv\",\"r\",newline='') as file:\n",
    "    reader = csv.reader(file,delimiter=',')\n",
    "    for row in tqdm(reader):\n",
    " \n",
    "        name = row[1].split(\"/\")[-1]\n",
    "        path = \"/home/jy/projects/yolo/dataprepare/patch1/\"+row[0]+\"/\"+name\n",
    "        r = requests.get(row[1], allow_redirects=True)\n",
    "        if not os.path.exists(\"/home/jy/projects/yolo/dataprepare/patch1/\"+row[0]+\"/\"):\n",
    "            os.makedirs(\"/home/jy/projects/yolo/dataprepare/patch1/\"+row[0]+\"/\")\n",
    "        if not os.path.exists(\"/home/jy/projects/yolo/dataprepare/patch1/\"+row[0]+\"/\"+name):\n",
    "            open(path, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dir,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip\"):\n",
    "    for f in files:\n",
    "        if 'zip.zip' in f:\n",
    "            os.rename(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip/\"+f,\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip/\"+f.split(\".\")[0]+\".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_d54809863_valid_2-2021_01_12_07_39_16-yolo.zip\n",
      "task_d88628921_valid_5-2021_01_15_06_25_01-yolo.zip\n",
      "task_c90841818_valid_2-2021_01_14_03_37_13-yolo.zip\n",
      "task_e57378973_valid_5-2021_01_14_07_53_54-yolo.zip\n",
      "task_d22710481_valid_1-2020_12_18_09_39_44-yolo.zip\n",
      "task_d22710484_valid_2-2021_01_15_03_36_52-yolo.zip\n",
      "task_d81141469_valid_5-2020_12_18_08_13_09-yolo.zip\n",
      "task_c90842327_valid_2-2021_01_15_02_02_12-yolo.zip\n",
      "task_e57379409_valid_3-2021_01_15_06_36_04-yolo.zip\n",
      "task_d81139089_valid_4-2021_01_12_09_07_13-yolo.zip\n",
      "task_d81142728_valid_3-2020_12_18_07_54_44-yolo.zip\n",
      "task_c90843625_valid_9-2020_12_29_06_08_38-yolo.zip\n",
      "task_d81141499_valid_1-2020_12_18_06_02_27-yolo.zip\n",
      "task_c94890223_valid_4-2021_01_12_07_54_40-yolo.zip\n",
      "task_e82843260_valid_4-2021_01_12_08_48_20-yolo.zip\n",
      "task_d00269541_valid_4-2021_01_12_08_30_22-yolo.zip\n",
      "task_e57379192_valid_5-2020_12_18_08_58_36-yolo.zip\n",
      "task_d81141708_valid_1-2020_12_18_07_23_32-yolo.zip\n",
      "task_d22710529_valid_2-2021_01_12_07_33_39-yolo.zip\n",
      "task_c90840818_valid_5-2021_01_14_05_50_39-yolo.zip\n",
      "task_d81141618_valid_2-2021_01_12_07_37_34-yolo.zip\n",
      "task_d81141532_valid_1-2021_01_11_07_51_29-yolo.zip\n",
      "task_e57379026_valid_3-2020_12_18_08_57_19-yolo.zip\n",
      "task_c90843561_valid_2-2020_12_29_06_06_10-yolo.zip\n",
      "task_e57379320_valid_5-2020_12_29_06_04_54-yolo.zip\n",
      "task_d00269638_valid_1-2021_01_14_05_43_50-yolo.zip\n",
      "task_d54809664_invalid_4-2021_01_12_07_56_34-yolo.zip\n",
      "task_d81141347_valid_4-2021_01_12_09_08_07-yolo.zip\n",
      "task_d81141293_valid_4-2021_01_12_08_26_49-yolo.zip\n",
      "task_e57379049_valid_5-2021_01_14_08_43_13-yolo.zip\n",
      "task_d81141661_invalid_4-2021_01_12_07_55_36-yolo.zip\n",
      "task_d81141599_invalid_4-2021_01_12_07_55_46-yolo.zip\n",
      "task_e57379121_valid_4-2021_01_12_08_46_10-yolo.zip\n",
      "task_d70008266_valid_4_ceram-2021_01_12_07_56_07-yolo.zip\n",
      "task_d81141430_valid_3-2021_01_13_07_59_27-yolo.zip\n",
      "task_d81141423_valid_4-2021_01_12_08_53_18-yolo.zip\n",
      "task_d81138712_valid_2-2021_01_15_02_04_36-yolo.zip\n",
      "task_e57379524_valid_3-2021_01_14_02_25_18-yolo.zip\n",
      "task_d54809686_valid_4_6_ceram-2021_01_12_07_56_22-yolo.zip\n",
      "task_c90842468_valid_3-2021_01_13_08_18_42-yolo.zip\n",
      "task_d81142158_valid_3-2021_01_15_06_44_10-yolo.zip\n",
      "task_e57378839_valid_5-2020_12_18_09_37_51-yolo.zip\n",
      "task_d88628881_valid_2-2021_01_15_05_37_17-yolo.zip\n",
      "task_c90843589_valid_5-2020_12_18_09_11_47-yolo.zip\n",
      "task_d81141552_valid_1-2020_12_18_09_24_10-yolo.zip\n",
      "task_d81139089_invalid_4-2021_01_12_07_55_56-yolo.zip\n",
      "task_e57381855_valid_2-2021_01_15_03_47_31-yolo.zip\n",
      "task_c90843647_valid_2-2021_01_14_02_06_34-yolo.zip\n",
      "task_e57381695_valid_5-2021_01_14_08_45_07-yolo.zip\n",
      "task_d88630050_valid_3-2020_11_09_10_50_19-yolo.zip\n",
      "task_d88628632_valid_5-2021_01_15_06_38_26-yolo.zip\n",
      "task_d81140262_valid_1-2020_12_18_07_47_40-yolo.zip\n",
      "task_d81141027_valid_3-2021_01_13_07_55_58-yolo.zip\n",
      "task_d81141414_valid_5-2021_01_14_10_04_46-yolo.zip\n",
      "task_d81143089_valid_3-2021_01_13_07_53_42-yolo.zip\n",
      "task_d81142566_valid_5-2021_01_15_06_43_22-yolo.zip\n",
      "task_d81141665_invalid_5-2021_01_14_03_44_57-yolo.zip\n",
      "task_e57379211_valid_3-2021_01_15_06_32_35-yolo.zip\n",
      "task_c90843157_valid_1-2021_01_14_05_45_26-yolo.zip\n",
      "task_d81139315_valid_3-2021_01_15_06_48_42-yolo.zip\n",
      "task_e57378903_valid_1-2020_12_18_05_56_43-yolo.zip\n",
      "task_d81141678_valid_2-2020_12_18_09_16_14-yolo.zip\n",
      "task_e66667792_valid_1-2020_12_18_05_47_40-yolo.zip\n",
      "task_e57379107_valid_5-2021_01_15_02_06_53-yolo.zip\n",
      "task_c94890625_valid_2-2021_01_15_02_03_38-yolo.zip\n",
      "task_d69997741_valid_3-2021_01_15_06_29_01-yolo.zip\n",
      "task_d81142947_valid_3-2021_01_15_05_58_14-yolo.zip\n",
      "task_d00268779_valid_2-2021_01_12_07_39_59-yolo.zip\n",
      "task_d81141572_valid_5-2021_01_15_06_31_07-yolo.zip\n",
      "task_d88628820_valid_1-2021_01_11_07_53_01-yolo.zip\n",
      "task_d70017095_valid_6-2021_01_15_02_25_53-yolo.zip\n",
      "task_d81141170_valid_2-2021_01_15_03_28_04-yolo.zip\n",
      "task_d81143241_valid_5-2020_12_18_05_54_02-yolo.zip\n",
      "task_d00269546_valid_5-2021_01_15_06_23_09-yolo.zip\n",
      "task_d81141482_valid_5-2021_01_12_07_23_38-yolo.zip\n",
      "task_d00269576_valid_3-2021_01_12_07_42_03-yolo.zip\n",
      "task_d00269528_valid_5-2021_01_15_06_28_59-yolo.zip\n",
      "task_e57379048_invalid_2-2020_11_09_10_59_52-yolo.zip\n",
      "task_c90843930_valid_1-2020_12_29_06_03_56-yolo.zip\n",
      "task_d00269560_valid_5-2021_01_14_08_46_52-yolo.zip\n",
      "task_d88628910_valid_2-2021_01_14_03_24_43-yolo.zip\n",
      "task_d81141599_valid_4-2021_01_12_08_21_04-yolo.zip\n",
      "task_e57379067_valid_3-2021_01_15_05_50_51-yolo.zip\n",
      "task_d81141409_valid_3-2021_01_13_07_57_53-yolo.zip\n",
      "task_d88629336_valid_3-2021_01_13_08_21_39-yolo.zip\n",
      "task_d00269192_valid_5-2021_01_15_06_44_47-yolo.zip\n",
      "task_d81142870_valid_5-2021_01_15_02_08_31-yolo.zip\n",
      "task_d81142102_valid_5-2021_01_15_06_40_27-yolo.zip\n",
      "task_d88628553_valid_3-2021_01_15_06_24_40-yolo.zip\n",
      "task_d81142014_valid_3-2021_01_15_06_15_16-yolo.zip\n",
      "task_d81141560_valid_4-2021_01_12_08_23_02-yolo.zip\n",
      "task_c90843689_valid_3-2021_01_13_07_29_16-yolo.zip\n",
      "task_d81141653_valid_5-2021_01_15_02_12_42-yolo.zip\n",
      "task_c90841769_valid_2-2020_12_18_07_44_10-yolo.zip\n",
      "task_e66669955_valid_1-2020_12_18_09_33_40-yolo.zip\n",
      "task_c90843803_valid_2-2020_12_18_05_49_54-yolo.zip\n",
      "task_d00269641_valid_5-2021_01_11_07_57_39-yolo.zip\n",
      "task_d81141460_valid_3-2021_01_13_07_41_55-yolo.zip\n",
      "task_e57379442_valid_5-2021_01_14_08_47_37-yolo.zip\n",
      "task_c90843476_valid_3-2021_01_15_06_40_07-yolo.zip\n",
      "task_e82843244_valid_2-2021_01_15_05_43_10-yolo.zip\n",
      "task_d88628646_valid_4-2021_01_12_07_55_27-yolo.zip\n",
      "task_e57378934_valid_2-2021_01_14_03_33_00-yolo.zip\n",
      "task_d81141061_valid_3-2021_01_13_07_54_54-yolo.zip\n",
      "task_c90843942_valid_1-2020_12_18_08_22_30-yolo.zip\n",
      "task_d81141315_valid_5-2021_01_15_06_27_20-yolo.zip\n",
      "task_d81141612_valid_2-2021_01_14_03_22_59-yolo.zip\n",
      "task_c90842488_valid_5-2021_01_15_06_35_05-yolo.zip\n",
      "task_e82840535_valid_3-2020_12_18_07_56_30-yolo.zip\n",
      "task_c90843479_valid_5-2021_01_15_02_11_11-yolo.zip\n",
      "task_d54809515_valid_4-2021_01_12_07_57_27-yolo.zip\n",
      "task_c90843485_valid_5-2021_01_14_05_54_11-yolo.zip\n",
      "task_c90843484_valid_3-2021_01_15_05_55_50-yolo.zip\n",
      "task_c90842542_valid_2-2021_01_14_03_11_10-yolo.zip\n",
      "task_d00267903_valid_1-2021_01_12_07_31_39-yolo.zip\n",
      "task_d88628528_valid_9-2020_12_18_09_21_00-yolo.zip\n",
      "task_e57378278_valid_3-2020_12_17_09_22_44-yolo.zip\n",
      "task_e66668396_valid_1-2021_01_14_05_48_19-yolo.zip\n",
      "task_d88628617_valid_3-2021_01_15_06_03_05-yolo.zip\n",
      "task_d00268712_valid_2-2021_01_12_07_35_01-yolo.zip\n",
      "task_c90842487_valid_1-2021_01_14_05_42_42-yolo.zip\n",
      "task_d81141670_invalid_4-2021_01_12_07_55_04-yolo.zip\n",
      "task_d00269607_valid_4-2021_01_12_08_38_06-yolo.zip\n",
      "task_d81142134_valid_4-2021_01_12_08_44_46-yolo.zip\n",
      "task_c90842467_valid_4-2021_01_12_07_59_22-yolo.zip\n",
      "task_d81140956_invalid_5-2021_01_14_05_48_48-yolo.zip\n",
      "task_c90844278_valid_1-2020_12_17_09_40_08-yolo.zip\n",
      "task_d81141290_valid_3-2021_01_13_07_50_04-yolo.zip\n",
      "task_d00268229_valid_2-2021_01_15_01_55_43-yolo.zip\n",
      "task_d00269480_valid_1-2020_12_17_09_42_14-yolo.zip\n",
      "task_d81141563_valid_5-2020_12_18_08_18_27-yolo.zip\n",
      "task_d88629662_valid_5-2021_01_15_06_32_46-yolo.zip\n",
      "task_d81142070_valid_1-2020_12_18_08_14_54-yolo.zip\n",
      "task_d00269554_valid_3-2021_01_13_07_45_38-yolo.zip\n",
      "task_d88628350_valid_1-2021_01_14_05_47_14-yolo.zip\n",
      "task_d81141980_valid_3-2020_12_18_09_10_28-yolo.zip\n",
      "task_d81141435_valid_1-2020_12_18_06_50_24-yolo.zip\n",
      "task_d88628651_valid_3-2021_01_13_07_39_20-yolo.zip\n",
      "task_d81140264_valid_3-2020_12_18_07_58_58-yolo.zip\n",
      "task_d00269544_valid_5-2021_01_15_06_41_40-yolo.zip\n"
     ]
    }
   ],
   "source": [
    "#rename and unzip thridbatch\n",
    "for root,dir,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip\"):\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        dirname = f.split(\".\")[0]\n",
    "#         os.rename(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip/\"+f,\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip/\"+f.split(\" \")[0]+\".zip\")\n",
    " \n",
    "#         os.mkdir('/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/')\n",
    "        subprocess.run(shlex.split(\"mkdir \"+\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"+dirname))\n",
    "        subprocess.run(shlex.split(\"unzip /home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_zip/\"+f+\" -d /home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"+dirname))\n",
    "#         print(\"unzip /home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"+f+\" -d /home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"+dirname)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dir,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_zip\"):\n",
    "    for f in files:\n",
    "        dirname = f.split(\".\")[0]\n",
    "#         os.rename(\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_zip/\"+f,\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_zip/\"+f.split(\" \")[0]+\".zip\")\n",
    " \n",
    "#         os.mkdir('/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip/')\n",
    "        subprocess.run(shlex.split(\"mkdir \"+\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip/\"+dirname))\n",
    "#         print(\"unzip /home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_zip/\"+f+\" -d /home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip/\"+dirname)\n",
    "        subprocess.run(shlex.split(\"unzip /home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_zip/\"+f+\" -d /home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip/\"+dirname))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syc label to o/c/s/obj/wash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thirdbatch\n",
    "for root,dir,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"):\n",
    "    dirs = [d for d in dir if len(d)>20]\n",
    "    for d in dirs:\n",
    "        path_d = os.path.join(root,d)\n",
    "        objname = os.path.join(path_d,'obj.names')\n",
    "        with open(objname,'r') as objnamefile:\n",
    "            names = objnamefile.readlines()\n",
    "        namedict = {}\n",
    "        for idx, name in enumerate(names):\n",
    "            name = name.rstrip()\n",
    "            namedict[name]=idx\n",
    "        try: \n",
    "            namedict['wash']\n",
    "        except KeyError:\n",
    "            namedict['wash']=4\n",
    "            \n",
    "        correct_order = [namedict['lidopen'],namedict['lidclose'],namedict['sink'],namedict['lidopenwithobj'],namedict['wash']]\n",
    "        txtlist = [txt for txt in os.listdir(os.path.join(path_d,'obj_train_data')) if txt[-3:]=='txt']\n",
    "        for txt in txtlist:\n",
    "            path_txt = os.path.join(path_d,'obj_train_data',txt)\n",
    "             \n",
    "            with open(path_txt,'r') as txtfile:\n",
    "                yolotxt = txtfile.readlines() \n",
    "            corrected = []\n",
    " \n",
    "            for li in yolotxt:\n",
    "                labels = str(correct_order.index(int(li[0])))\n",
    "                rest = li[1:]\n",
    "                corrected.append(labels+rest)\n",
    "            with open(path_txt,'w') as txtfilewriter:\n",
    "                for cor in corrected:\n",
    "                    txtfilewriter.write(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dir,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip\"):\n",
    "    dirs = [d for d in dir if len(d)>20]\n",
    "    for d in dirs:\n",
    "        path_d = os.path.join(root,d)\n",
    "        objname = os.path.join(path_d,'obj.names')\n",
    "        with open(objname,'r') as objnamefile:\n",
    "            names = objnamefile.readlines()\n",
    "        namedict = {}\n",
    "        for idx, name in enumerate(names):\n",
    "            name = name.rstrip()\n",
    "            namedict[name]=idx\n",
    "        try: \n",
    "            namedict['wash']\n",
    "        except KeyError:\n",
    "            namedict['wash']=4\n",
    "            \n",
    "        correct_order = [namedict['lidopen'],namedict['lidclose'],namedict['sink'],namedict['lidopenwithobj'],namedict['wash']]\n",
    "        txtlist = [txt for txt in os.listdir(os.path.join(path_d,'obj_train_data')) if txt[-3:]=='txt']\n",
    "        for txt in txtlist:\n",
    "            path_txt = os.path.join(path_d,'obj_train_data',txt)\n",
    "             \n",
    "            with open(path_txt,'r') as txtfile:\n",
    "                yolotxt = txtfile.readlines() \n",
    "            corrected = []\n",
    " \n",
    "            for li in yolotxt:\n",
    "                labels = str(correct_order.index(int(li[0])))\n",
    "                rest = li[1:]\n",
    "                corrected.append(labels+rest)\n",
    "            with open(path_txt,'w') as txtfilewriter:\n",
    "                for cor in corrected:\n",
    "                    txtfilewriter.write(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sink only data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip\"):\n",
    "    dirs = [d for d in dirs if len(d)>20]\n",
    "    for d in dirs:\n",
    "        path_images = os.path.join(root,d,'obj_train_data')\n",
    "        txts = os.listdir(path_images)\n",
    "        txts = [tst for tst in txts if tst[-3:]=='txt']\n",
    "        sink_candi = []\n",
    "        for txt in txts:\n",
    "            with open(os.path.join(path_images,txt),'r') as label:\n",
    "                labels = label.readlines()\n",
    "            for line in labels:\n",
    "                if line[0]=='0':\n",
    "                    sink_candi.append(os.path.join(path_images,txt))\n",
    "                    break\n",
    "        try:\n",
    "            samples = random.sample(sink_candi,90)\n",
    "        except ValueError:\n",
    "            samples = sink_candi\n",
    "        \n",
    "        dst_parent = \"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip_selected180\"\n",
    "        dst = os.path.join(dst_parent,d)\n",
    "        if not os.path.exists(dst):\n",
    "            os.makedirs(dst)\n",
    "        for sample in samples:\n",
    "            src_name = sample.split('/')[-1].split('.')[0]\n",
    "            \n",
    "            dst_png_name='%s_%s.PNG'%(d,src_name)\n",
    "            dst_txt_name='%s_%s.txt'%(d,src_name)\n",
    "            \n",
    "            png_src_path = sample[:-3]+'PNG'\n",
    "            txt_src_path = sample\n",
    "            \n",
    "            png_dst_path = os.path.join(dst,dst_png_name)\n",
    "            txt_dst_path = os.path.join(dst,dst_txt_name)\n",
    "            \n",
    "            with open(txt_src_path,'r') as txt_src:\n",
    "                txt_src_labels = txt_src.readlines()\n",
    "            txt_dst_out = []\n",
    "            \n",
    "            with open(txt_dst_path,'w')as txt_dst_file:\n",
    "                for tsl in txt_src_labels:\n",
    "                    if tsl[0] == '0':\n",
    "                        txt_dst_file.write(tsl)\n",
    "            copyfile(png_src_path,png_dst_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move from obj_train_data to outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thirdbatch machine only  0,1,3\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"):\n",
    "    dirs = [d for d in dirs if 'obj_train' in d]\n",
    "\n",
    "    for d in dirs:\n",
    "        dirname = root.split('/')[-1]\n",
    "        if not os.path.exists('/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/'+dirname):\n",
    "            os.makedirs('/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/'+dirname)\n",
    "        dstdir = '/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/'+dirname\n",
    "        otdpath = os.path.join(root,d)\n",
    "        files = os.listdir(otdpath)\n",
    "        txts = [f for f in files if f[-3:]=='txt']\n",
    "        o=0\n",
    "        c=0\n",
    "        obj=0\n",
    "        o_candi = []\n",
    "        c_candi = []\n",
    "        obj_candi = []\n",
    "        for txt in txts:\n",
    "            txtpath = os.path.join(otdpath,txt)\n",
    "            with open(txtpath,'r') as txtfile:\n",
    "                lines = txtfile.readlines()\n",
    "            for l in lines:\n",
    "                if l[0]=='0':\n",
    "                    o+=1\n",
    "                    o_candi.append(txtpath)\n",
    "                if l[0]=='1':\n",
    "                    c+=1\n",
    "                    c_candi.append(txtpath)\n",
    "                if l[0]=='3':\n",
    "                    obj+=1\n",
    "                    obj_candi.append(txtpath)\n",
    "        try:\n",
    "            o_samples = random.sample(o_candi,80)\n",
    "        except ValueError:\n",
    "            o_samples = o_candi\n",
    "            \n",
    "        try:\n",
    "            c__samples = random.sample(c_candi,80)\n",
    "        except ValueError:\n",
    "            c__samples = c_candi     \n",
    "            \n",
    "        try:\n",
    "            obj__samples = random.sample(obj_candi,80)\n",
    "            \n",
    "        except ValueError:\n",
    "            obj__samples = obj_candi\n",
    "        \n",
    "#         pngpath = txtpath.split('.')[0]+'.png'\n",
    "        samples = [o_samples,c__samples,obj__samples]\n",
    "        for sample in samples:\n",
    "            for txtpath in sample:\n",
    "                pngpath_src = txtpath.split('.')[0]+'.PNG'\n",
    "                pngpath_dst = dstdir+'/'+dirname+'_'+txtpath.split('/')[-1].split('.')[0]+'.PNG'\n",
    "                txtpath_dst = dstdir+'/'+dirname+'_'+txtpath.split('/')[-1]\n",
    "                line_output = []\n",
    "                with open(txtpath,'r') as label:\n",
    "                    labels = label.readlines()\n",
    "                for line in labels:\n",
    "                    if line[0]!='2' and  line[0]!='4' :\n",
    "                        line_output.append(line)\n",
    "                with open(txtpath_dst, 'w') as f:\n",
    "                    for item in line_output:\n",
    "                        f.write(\"%s\" % item)\n",
    "#                 copyfile(txtpath,txtpath_dst)\n",
    "                copyfile(pngpath_src,pngpath_dst)\n",
    "#         print(o_samples)\n",
    "#         print(c__samples)\n",
    "#         print(obj__samples)\n",
    "        \n",
    "#         print(\"o: %s, c: %s, obj:%s\" %(len(o_samples),len(c__samples),len(obj__samples)))\n",
    "                \n",
    "                \n",
    "        \n",
    "#         path = os.path.join(root,d)\n",
    "#         files = os.listdir(path)\n",
    "#         copyfile(png_src_path,png_dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second batch label adjusting chagne 1_0 1_1 1_3 to same device\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/secondbatch_yolo_machine/\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        dirpath = os.path.join(root,d,)\n",
    "        dirfiles = os.listdir(dirpath)\n",
    "        dirfiles_txt = [f for f in dirfiles if f[-3:]=='txt']\n",
    "#         print(label)\n",
    "        for txt in dirfiles_txt:\n",
    "            txt = os.path.join(dirpath,txt)\n",
    "            with open(txt,'r') as content:\n",
    "                lines = content.readlines()\n",
    "            \n",
    "            with open(txt, 'w') as f:\n",
    "                for item in lines:\n",
    "                    item = item.split(' ')\n",
    "                    item[0]=label\n",
    "                    item = ' '.join(item)\n",
    "\n",
    "                    f.write(\"%s\" % item)\n",
    "                \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first batch label adjusting chagne 1_0 1_1 1_3 to same device\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        if label == 'd':\n",
    "            label = d.split('_')[1][0]\n",
    "        if label == 'v':\n",
    "            label = d.split('_')[2][0]\n",
    "        if label == 's':\n",
    "            label = d.split('_')[2][0]\n",
    "\n",
    "        if 'task_vaild' in d or 'task_notvaild' in d:\n",
    "            label = d.split('_')[2][0]\n",
    "        dirpath = os.path.join(root,d,)\n",
    "        dirfiles = os.listdir(dirpath)\n",
    "        dirfiles_txt = [f for f in dirfiles if f[-3:]=='txt']\n",
    "        for txt in dirfiles_txt:\n",
    "            txt = os.path.join(dirpath,txt)\n",
    "            with open(txt,'r') as content:\n",
    "                lines = content.readlines()\n",
    "            with open(txt, 'w') as f:\n",
    "                for item in lines:\n",
    "                    item = item.split(' ')\n",
    "                    item[0]=label\n",
    "                    item = ' '.join(item)\n",
    "\n",
    "                    f.write(\"%s\" % item)\n",
    "                \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thrid batch label adjusting chagne 1_0 1_1 1_3 to same device\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        dirpath = os.path.join(root,d,)\n",
    "        dirfiles = os.listdir(dirpath)\n",
    "        dirfiles_txt = [f for f in dirfiles if f[-3:]=='txt']\n",
    "        for txt in dirfiles_txt:\n",
    "            txt = os.path.join(dirpath,txt)\n",
    "            with open(txt,'r') as content:\n",
    "                lines = content.readlines()\n",
    "            with open(txt, 'w') as f:\n",
    "                for item in lines:\n",
    "                    item = item.split(' ')\n",
    "                    item[0]=label\n",
    "                    item = ' '.join(item)\n",
    "\n",
    "                    f.write(\"%s\" % item)\n",
    "                \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"firstbatch/unzips/\"):\n",
    "    dirs = [d for d in dirs if 'obj_train' in d]\n",
    "    \n",
    "    for d in dirs:\n",
    "        path = os.path.join(root,d)\n",
    "        files = os.listdir(path)\n",
    "        copyfile(png_src_path,png_dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sink only data collection fist batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"firstbatch/unzips/\"):\n",
    "    for d in dirs:\n",
    "        if 'train'  in d :\n",
    "\n",
    "            path_images = os.path.join(root,d)\n",
    "            txts = os.listdir(path_images)\n",
    "            txts = [tst for tst in txts if tst[-3:]=='txt' and 'classification' not in tst]\n",
    "            sink_candi = []\n",
    "            for txt in txts:\n",
    "                with open(os.path.join(path_images,txt),'r') as label:\n",
    "                    labels = label.readlines()\n",
    "                for line in labels:\n",
    "                    if line[0]=='2':\n",
    "                        sink_candi.append(os.path.join(path_images,txt))\n",
    "                        break\n",
    "            try:\n",
    "                samples = random.sample(sink_candi,180)\n",
    "            except ValueError:\n",
    "                samples = sink_candi\n",
    "\n",
    "            dst_parent = \"firstbatch/firstbatch_sinkonly\"\n",
    "            dst = os.path.join(dst_parent,d)\n",
    "            if not os.path.exists(dst):\n",
    "                os.makedirs(dst)\n",
    "            for sample in samples:\n",
    "                src_name = sample.split('/')[-1].split('.')[0]\n",
    "\n",
    "                dst_png_name='%s_%s.PNG'%(d,src_name)\n",
    "                dst_txt_name='%s_%s.txt'%(d,src_name)\n",
    "\n",
    "                png_src_path = sample[:-3]+'PNG'\n",
    "                txt_src_path = sample\n",
    "\n",
    "                png_dst_path = os.path.join(dst,dst_png_name)\n",
    "                txt_dst_path = os.path.join(dst,dst_txt_name)\n",
    "\n",
    "                with open(txt_src_path,'r') as txt_src:\n",
    "                    txt_src_labels = txt_src.readlines()\n",
    "                txt_dst_out = []\n",
    "\n",
    "                with open(txt_dst_path,'w')as txt_dst_file:\n",
    "                    for tsl in txt_src_labels:\n",
    "                        if tsl[0] == '2':\n",
    "                            txt_dst_file.write(tsl)\n",
    "                copyfile(png_src_path,png_dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sink only data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    " transform_flip = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='yolo'))\n",
    "\n",
    "transform_rotate = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='yolo'))\n",
    "transform_ShiftScaleRotate = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=90, p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "], bbox_params=A.BboxParams(format='yolo'))\n",
    "alies_transform = ['flip','rotate','shiftrotate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/\"):\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/secondbatch_yolo_machine\"):\n",
    "    \n",
    "    for f in files:\n",
    "        for alies in alies_transform:\n",
    "            if alies in f:\n",
    "                try:\n",
    "                    os.remove(os.path.join(root,f))\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 66/70 [01:53<00:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_003990.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005170.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005360.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004950.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004120.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004900.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005220.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004860.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005160.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004600.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004210.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_003990.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004850.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005250.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004600.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005120.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005170.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004120.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004900.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005100.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 67/70 [01:54<00:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004670.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_004350.txt\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/task_d54809682_valid_1-2020_10_27_07_38_16-yolo/task_d54809682_valid_1-2020_10_27_07_38_16-yolo_frame_005010.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [02:00<00:00,  1.72s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# third batch augmentation\n",
    "\n",
    "# for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected/\"):\n",
    "# for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/secondbatch_yolo_machine\"):\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/\"):\n",
    "    dirs = [d for d in dirs if 'task' in d]\n",
    "    \n",
    "    for d in  tqdm( dirs):\n",
    "        allfile = []\n",
    "        dirpath = os.path.join(root,d)\n",
    "        files = os.listdir(dirpath)\n",
    "        files = [file for file in files if file[-3:]=='txt']\n",
    "        files = [os.path.join(dirpath,file) for file in files]\n",
    "#         files = [os.path.join(root,file) for file in files if file[-3:]=='txt' and 'train' not in file and 'obj' not in file]\n",
    "#         allfile+=files\n",
    "        allfile = files\n",
    "    \n",
    "        sample_num = round(len(allfile)*0.17)\n",
    "        flipfiles = random.sample(allfile,sample_num)\n",
    "        rotatefiles = random.sample(allfile,sample_num)\n",
    "        ShiftScale = random.sample(allfile,sample_num)\n",
    "        filelist = [flipfiles,rotatefiles,ShiftScale]\n",
    "    \n",
    "        transforms = [transform_flip,transform_rotate,transform_ShiftScaleRotate]\n",
    "\n",
    "        for idx,file in enumerate( filelist):\n",
    "            for f in file:\n",
    "                txtpath =  f \n",
    "                pngpath =  f [:-3]+'PNG'\n",
    "                image = cv2.imread(pngpath)\n",
    "\n",
    "                boxes = []\n",
    "        #         print(txtpath)\n",
    "                try:\n",
    "                    with open (txtpath,'r')as txt:\n",
    "                        lines = txt.readlines()\n",
    "        #                 print(txtpath)\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print(txtpath)\n",
    "                    continue\n",
    "                for line in lines:\n",
    "                    line = line.rstrip()\n",
    "                    label = line[0]\n",
    "                    box = line[2:].split(\" \")\n",
    "                    box = [float(b) for b in box]\n",
    "                    box.append(label)\n",
    "                    boxes.append(box)\n",
    "                \n",
    "                transform = transforms[idx]\n",
    "                try:\n",
    "                    transformed = transform(image=image, bboxes=boxes)\n",
    "                except :\n",
    "                    print(txtpath)\n",
    "                    continue\n",
    "                transformed_image = transformed['image']\n",
    "                transformed_bboxes = transformed['bboxes']\n",
    "#                 transformed_class_labels = transformed_bboxes[-1]\n",
    "                \n",
    "#                 print(transformed_class_labels)\n",
    "#                 if '630881' in f:\n",
    "#                     print(boxes)\n",
    "#                     print(transformed_bboxes)\n",
    "\n",
    "                out = []\n",
    "                for b in transformed_bboxes:\n",
    "                    b = list(b)\n",
    "                    b.insert(0, b.pop())\n",
    "                    out.append(b)\n",
    "#                 print(out)\n",
    "                save_prefix = str(alies_transform[idx])\n",
    "                save_path = '/'.join(pngpath.split(\"/\")[:-1])\n",
    "                png_save_path = save_path+'/'+save_prefix+'_'+pngpath.split(\"/\")[-1]\n",
    "                txt_save_path = save_path+'/'+save_prefix+'_'+txtpath.split(\"/\")[-1]\n",
    "                \n",
    "                \n",
    "                \n",
    "                with open(txt_save_path,'w') as test:\n",
    "                    for o in out:\n",
    "                        test.write(' '.join(map(str,o)))\n",
    "                        test.write('\\n')\n",
    "\n",
    "                cv2.imwrite(png_save_path,transformed_image)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:19<00:00, 54.01it/s]\n",
      "100%|██████████| 1040/1040 [00:19<00:00, 54.06it/s]\n",
      "100%|██████████| 1040/1040 [00:20<00:00, 50.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# second batch sink only missclassified\n",
    "allfile = []\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/sink_only_secondbatch_missclassified_unzip_selected180\"):\n",
    "    \n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='txt' and 'train' not in file and 'obj' not in file]\n",
    "    allfile+=files\n",
    "#     for f in files:\n",
    "# #         if len(f)<140:\n",
    "#             print(f)\n",
    "    \n",
    "sample_num = round(len(allfile)*0.17)\n",
    "flipfiles = random.sample(allfile,sample_num)\n",
    "rotatefiles = random.sample(allfile,sample_num)\n",
    "ShiftScale = random.sample(allfile,sample_num)\n",
    "filelist = [flipfiles,rotatefiles,ShiftScale]\n",
    "    \n",
    "transforms = [transform_flip,transform_rotate,transform_ShiftScaleRotate]\n",
    "    \n",
    "for idx,file in enumerate( filelist):\n",
    "    for f in tqdm( file):\n",
    "        txtpath =  f \n",
    "        pngpath =  f [:-3]+'PNG'\n",
    "        image = cv2.imread(pngpath)\n",
    "\n",
    "        boxes = []\n",
    "#         print(txtpath)\n",
    "        try:\n",
    "            with open (txtpath,'r')as txt:\n",
    "                lines = txt.readlines()\n",
    "#                 print(txtpath)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(txtpath)\n",
    "            continue\n",
    "        for line in lines:\n",
    "            line = line.rstrip()\n",
    "            box = line[2:].split(\" \")\n",
    "            box = [float(b) for b in box]\n",
    "            box.append('2')\n",
    "            boxes.append(box)\n",
    "#         print(boxes)\n",
    "        transform = transforms[idx]\n",
    "        try:\n",
    "            transformed = transform(image=image, bboxes=boxes, class_labels=['2'])\n",
    "        except :\n",
    "            print(txtpath)\n",
    "            continue\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "        \n",
    "        transformed_class_labels = transformed['class_labels']\n",
    "#         print(transformed_class_labels)\n",
    "#         print(transformed_bboxes)\n",
    "        \n",
    "        out = []\n",
    "        for b in transformed_bboxes:\n",
    "            b = list(b)\n",
    "            b.pop()\n",
    "             \n",
    "            b.insert(0,'2')\n",
    "            out.append(b)\n",
    "        \n",
    "        save_prefix = str(alies_transform[idx])\n",
    "        save_path = '/'.join(pngpath.split(\"/\")[:-1])\n",
    "        png_save_path = save_path+'/'+save_prefix+'_'+pngpath.split(\"/\")[-1]\n",
    "        txt_save_path = save_path+'/'+save_prefix+'_'+txtpath.split(\"/\")[-1]\n",
    "        with open(txt_save_path,'w') as test:\n",
    "            for o in out:\n",
    "                test.write(' '.join(map(str,o)))\n",
    "                test.write('\\n')\n",
    "            \n",
    "        cv2.imwrite(png_save_path,transformed_image)\n",
    "\n",
    "        \n",
    "#         print(save_path)\n",
    "#         print(png_save_path)\n",
    "#         print(txt_save_path)\n",
    "#         break\n",
    "#         cv2.imwrite(path+\"ShiftScaleRotate_\"+f,augmented_image)\n",
    "        \n",
    "#         print(transformed_bboxes[0][1])\n",
    "#         print(transformed_image.shape)\n",
    "#         h,w,_ = transformed_image.shape\n",
    "#         x1 = int((float(transformed_bboxes[0][0])*w))\n",
    "#         y1 = int((float(transformed_bboxes[0][1])*h))\n",
    "#         xw = int((float(transformed_bboxes[0][2])*w/2))\n",
    "#         xh =  int((float(transformed_bboxes[0][3]))*h/2)\n",
    "#         print((x1,y1),(x1,y1),(h,w))\n",
    "#         cv2.rectangle(transformed_image, (x1-xw,y1-xh), (x1+xw,y1+xh), (255,0,0),2) \n",
    "\n",
    "        \n",
    "#         x1 = int((float(boxes[0][0])*w))\n",
    "#         y1 = int((float(boxes[0][1])*h))\n",
    "#         xw = int((float(boxes[0][2])*w/2))\n",
    "#         xh =  int((float(boxes[0][3]))*h/2)\n",
    "        \n",
    "        \n",
    "#         cv2.rectangle(image, (x1-xw,y1-xh), (x1+xw,y1+xh), (255,0,0),2) \n",
    "        \n",
    "#         cv2.imshow('image',image)\n",
    "#         cv2.imshow('transformed_image',transformed_image)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinkonly_1and2batch/secondbatch_sinkonly/task_d88629340_invalid_0-2020_11_16_02_10_20-yolo/task_d88629340_invalid_0-2020_11_16_02_10_20-yolo_frame_002490.txt\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(\"sinkonly_1and2batch\"):\n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='txt']\n",
    "    for f in files:\n",
    "        if not os.path.exists(f [:-3]+'PNG'):\n",
    "            print(f)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allfile = []\n",
    "for root,dirs,files in os.walk(\"sinkonly_1and2batch\"):\n",
    "    \n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='txt']\n",
    "    allfile+=files\n",
    "    \n",
    "train,val = train_test_split(allfile,test_size=0.35, random_state=42)\n",
    "val,test = train_test_split(val,test_size=0.33, random_state=42)\n",
    "\n",
    "for f in train:\n",
    "    dst = 'sink_only/labels/train/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "for f in test:\n",
    "    dst = 'sink_only/labels/test/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "for f in val:\n",
    "    dst = 'sink_only/labels/val/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "    \n",
    "for f in train:\n",
    "    f = f [:-3]+'PNG'\n",
    "    dst = 'sink_only/images/train/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "for f in test:\n",
    "    f = f [:-3]+'PNG'\n",
    "    \n",
    "    dst = 'sink_only/images/test/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "for f in val:\n",
    "    f = f [:-3]+'PNG'\n",
    "    \n",
    "    dst = 'sink_only/images/val/'\n",
    "    if not os.path.isdir(dst):\n",
    "        os.makedirs(dst)\n",
    "    dst_file = dst+f.split('/')[-1]\n",
    "    copyfile(f,dst_file)\n",
    "# for file in allfile:\n",
    "#     print(file)\n",
    "    \n",
    "    \n",
    "# for rs,ds,fs in os.walk(\"sinkonly_1and2batch\"):\n",
    "    \n",
    "#     for d in ds:\n",
    "#         fs = os.listdir(\"sink_only/pots/\"+d)\n",
    " \n",
    "#         train,val = train_test_split(fs,test_size=0.35, random_state=42)\n",
    "#         val,test = train_test_split(val,test_size=0.15, random_state=42)\n",
    "        \n",
    "#         if not os.path.isdir(\"unzips_classify/train/\"+d):\n",
    "#             os.mkdir(\"unzips_classify/train/\"+d)\n",
    "#         if not os.path.isdir(\"unzips_classify/test/\"+d):\n",
    "#             os.mkdir(\"unzips_classify/test/\"+d)\n",
    "#         if not os.path.isdir(\"unzips_classify/val/\"+d):\n",
    "#             os.mkdir(\"unzips_classify/val/\"+d)\n",
    "#         for i in train:\n",
    "#             copyfile(os.path.join(rs,d,i),\"unzips_classify/train/\"+d+\"/\"+i)\n",
    "#         for i in val:\n",
    "#             copyfile(os.path.join(rs,d,i),\"unzips_classify/val/\"+d+\"/\"+i)\n",
    "#         for i in test:\n",
    "#             copyfile(os.path.join(rs,d,i),\"unzips_classify/test/\"+d+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sink only 2 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfile = []\n",
    "for root,dirs,files in os.walk(\"sinkonly_1and2batch\"):\n",
    "    \n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='txt']\n",
    "    allfile+=files\n",
    "for f in allfile:\n",
    "    with open(f,'r')as readf:\n",
    "        lines = readf.readlines()\n",
    "    out = []\n",
    "    for li in lines:\n",
    "        li = '0'+li[1:]\n",
    "        out.append(li)\n",
    "    with open(f,'w')as writef:\n",
    "        for o in out:\n",
    "            writef.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second batch nohand image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohand_candi = []\n",
    "for root,dirs,files in os.walk(\"secondbatch/secondbatch_unzips/\"):\n",
    "    dirs = [d for d in dirs if len(d)>20]\n",
    "    for d in dirs:\n",
    "        path_images = os.path.join(root,d,'obj_train_data')\n",
    "        txts = os.listdir(path_images)\n",
    "        txts = [os.path.join(path_images,tst) for tst in txts if tst[-3:]=='txt']\n",
    "        for txt in txts:\n",
    "            with open(txt,'r')as txtreader:\n",
    "                txtlines = txtreader.readlines()\n",
    "            \n",
    "            for line in txtlines:\n",
    "                if line[0]!='4':\n",
    "                    nohand_candi.append(txt)\n",
    "                    break\n",
    "nohand_candi = random.sample(nohand_candi,15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc in nohand_candi:\n",
    "    with open(nc,'r')as txtreader:\n",
    "        txtlines = txtreader.readlines()\n",
    "    pngpath = nc[:-3]+'PNG'\n",
    "    image = cv2.imread(pngpath)\n",
    "    h,w,_ = image.shape\n",
    "    for idx,line in enumerate(txtlines):\n",
    "        if line[0]=='2':\n",
    "            sinklocation = line.split(\" \")[1:]\n",
    "            sinklocation = [float(i) for i in sinklocation]\n",
    "            x1 = int((float(sinklocation[0])*w))\n",
    "            y1 = int((float(sinklocation[1])*h))\n",
    "            xw = int((float(sinklocation[2]))*w/2)\n",
    "            xh = int((float(sinklocation[3]))*h/2)\n",
    "            crop_img = image[y1-xh:y1+xh, x1-xw:x1+xw]\n",
    "            \n",
    " \n",
    "            \n",
    "            \n",
    "            savepath = '/home/jy/projects/imgs/dataprepare/secondbatch_classify/secondbatch_nohand'\n",
    "            savepath = savepath +'/'+ pngpath.split(\"/\")[2]\n",
    "            imname = savepath+'/'+pngpath.split(\"/\")[2]+'_'+pngpath.split(\"/\")[-1][:-3]+'PNG'\n",
    "            \n",
    "            if not os.path.isdir(savepath):\n",
    "                os.makedirs(savepath)\n",
    "            cv2.imwrite(imname, crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand and nohand data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " transform_flip = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "transform_rotate = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "transform_ShiftScaleRotate = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=90, p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "alies_transform = ['flip','rotate','shiftrotate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 4416/14034 [00:05<00:13, 736.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-86eac5336fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mpng_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpngpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng_save_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allfile = []\n",
    "for root,dirs,files in os.walk(\"handclassify\"):\n",
    "    \n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='PNG']\n",
    "    allfile+=files\n",
    "#     for f in files:\n",
    "# #         if len(f)<140:\n",
    "#             print(f)\n",
    "    \n",
    "sample_num = round(len(allfile)*0.17)\n",
    "flipfiles = random.sample(allfile,sample_num)\n",
    "rotatefiles = random.sample(allfile,sample_num)\n",
    "ShiftScale = random.sample(allfile,sample_num)\n",
    "filelist = [flipfiles,rotatefiles,ShiftScale]\n",
    "    \n",
    "transforms = [transform_flip,transform_rotate,transform_ShiftScaleRotate]\n",
    "    \n",
    "for idx,file in enumerate( filelist):\n",
    "    for f in tqdm( file):\n",
    "         \n",
    "        pngpath =  f [:-3]+'PNG'\n",
    "        image = cv2.imread(pngpath)\n",
    "\n",
    "        transform = transforms[idx]\n",
    "        try:\n",
    "            transformed = transform(image=image)\n",
    "        except :\n",
    "            print(txtpath)\n",
    "            continue\n",
    "        transformed_image = transformed['image']\n",
    "        \n",
    "#         print(transformed_class_labels)\n",
    "#         print(transformed_bboxes)\n",
    "        \n",
    "       \n",
    "        \n",
    "        save_prefix = str(alies_transform[idx])\n",
    "        save_path = '/'.join(pngpath.split(\"/\")[:-1])\n",
    "        png_save_path = save_path+'/'+save_prefix+'_'+pngpath.split(\"/\")[-1]\n",
    " \n",
    "        cv2.imwrite(png_save_path,transformed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move hand 1&2 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"handclassify1&2/secondbatch_nohand\"):\n",
    "    files = [os.path.join(root,file) for file in files if file[-3:]=='PNG']\n",
    "    for f in files:\n",
    "        \n",
    "        copyfile(f,'handclassify1&2/sec_nohand/'+f.split('/')[-2]+f.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohand\n",
      "sec_nohand\n",
      "hand\n",
      "sec_hand\n",
      "handclassify1&2/sec_hand/task_d81141612_invalid_2-2020_11_20_01_57_12-yoloframe_002400.PNG\n",
      "hand\n",
      "firstbatch_hand\n",
      "handclassify1&2/firstbatch_hand/flip_task_vaild_5_0-2020_10_28_04_08_36-yolo_frame_024850.PNG\n",
      "nohand\n",
      "firstbatch_nohand\n",
      "handclassify1&2/firstbatch_hand/flip_task_vaild_5_0-2020_10_28_04_08_36-yolo_frame_024850.PNG\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(\"handclassify1&2\"):\n",
    "    for d in dirs:\n",
    "        if '_nohand' in d:\n",
    "            print('nohand')\n",
    "            print(d)\n",
    " \n",
    "            for r,ds,fs in os.walk(path):\n",
    "                fs = [os.path.join(r,file) for file in fs if file[-3:]=='PNG']\n",
    "                print(fs[0])\n",
    "                \n",
    "                for f in fs:\n",
    "                    filename = f.split('/')[-1]\n",
    "                    copyfile(f,'handclassify/nohand/'+filename)\n",
    "        elif  '_hand' in d: \n",
    "            print('hand')\n",
    "            print(d)\n",
    "            \n",
    "            path = os.path.join(root,d)\n",
    "            for r,ds,fs in os.walk(path):\n",
    "                fs = [os.path.join(r,file) for file in fs if file[-3:]=='PNG']\n",
    "                for f in fs:\n",
    "                    filename = f.split('/')[-1]\n",
    "                    copyfile(f,'handclassify/hand/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand classify train test val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"handclassify\"):\n",
    "    for d in dirs:\n",
    "        path = os.path.join(root,d)\n",
    "        images = os.listdir(path)\n",
    "        images = [os.path.join(path,file) for file in images if file[-3:]=='PNG']\n",
    "        train,val = train_test_split(images,test_size=0.35, random_state=42)\n",
    "        val,test = train_test_split(val,test_size=0.33, random_state=42)\n",
    "        for f in train:\n",
    "            dst ='train/%s/'%d\n",
    "            if not os.path.isdir(dst):\n",
    "                os.makedirs(dst)\n",
    "            dst_file = dst+f.split('/')[-1]\n",
    "            copyfile(f,dst_file)\n",
    "        for f in test:\n",
    "            dst ='test/%s/'%d\n",
    "            if not os.path.isdir(dst):\n",
    "                os.makedirs(dst)\n",
    "            dst_file = dst+f.split('/')[-1]\n",
    "            copyfile(f,dst_file)\n",
    "        for f in val:\n",
    "            dst = 'val/%s/'%d\n",
    "            if not os.path.isdir(dst):\n",
    "                os.makedirs(dst)\n",
    "            dst_file = dst+f.split('/')[-1]\n",
    "            copyfile(f,dst_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second batch individual o/c/obj selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/second_batch_individual\"):\n",
    "    dirs = [d for d in dirs if d in ['1','2','3','4','5']]\n",
    "    dirpaths = [os.path.join(root,d) for d in dirs ]\n",
    "#     print(dirpaths)\n",
    "    for dirpath in dirpaths:\n",
    "        cpath = os.path.join(dirpath,'lidopen') \n",
    "        opath = os.path.join(dirpath,'lidclose') \n",
    "        objpath = os.path.join(dirpath,'lidopenwithobj') \n",
    "        folders = [cpath,opath,objpath]\n",
    "        for folder in folders:\n",
    "            picfolder = os.path.join(folder,'picture') \n",
    "            txtfolder = os.path.join(folder,'txt')\n",
    "            pictures = os.listdir(picfolder)\n",
    "            pictures.sort() \n",
    "            res = [list(i) for j, i in groupby(pictures, lambda a: a.split('_')[1])]  \n",
    "            for group in res:\n",
    "                try:\n",
    "                    o_samples = random.sample(group,80)\n",
    "                except ValueError:\n",
    "                    o_samples = group\n",
    "                for sample in o_samples:\n",
    "                    pngpath = os.path.join(picfolder,sample)  \n",
    "                    txtname = sample.split('.')[0]+'.txt'\n",
    "                    txtpath = os.path.join(txtfolder,txtname)  \n",
    "                    dirname = \"_\".join(sample.split('_')[:-2])\n",
    "                    dst = '/home/jy/projects/imgs/dataprepare/secondbatch/secondbatch_yolo_machine/'+dirname\n",
    "                    if not os.path.exists(dst):\n",
    "                        os.makedirs(dst)\n",
    "                    pngpath_dst = os.path.join(dst,sample)  \n",
    "                    txtpath_dst = os.path.join(dst,txtname)  \n",
    "                    line_output=[]\n",
    "                    with open(txtpath,'r') as label:\n",
    "                        labels = label.readlines()\n",
    "                    for line in labels:\n",
    "                        if line[0]!='2' and  line[0]!='4' :\n",
    "                            line_output.append(line)\n",
    "                    with open(txtpath_dst, 'w') as f:\n",
    "                        for item in line_output:\n",
    "                            f.write(\"%s\" % item)\n",
    "                    copyfile(pngpath,pngpath_dst)\n",
    "#                     copyfile(txtpath,txtpath_dst)\n",
    "         \n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first batch yolo train dataprepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first batch remvoe classfi and add obj train data folder\n",
    "for root,dirs,files in os.walk('firstbatch/unzips'):\n",
    "#     for d in dirs:\n",
    "#         if 'train' in d:\n",
    "#             file = os.listdir(os.path.join(root,d))\n",
    "#             os.mkdir(os.path.join(root,d,'obj_train_data'))\n",
    "#             for f in file:\n",
    "#                 os.rename(os.path.join(root,d,f),os.path.join(root,d,'obj_train_data',f))\n",
    "#     for d in dirs:\n",
    "    for f in files:\n",
    "        if 'classif' in f:\n",
    "            os.remove(os.path.join(root,f))\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train3_5_0_d00000000\n",
      "train3_5_0_d00000000\n",
      "train3_5_0_d00000000\n",
      "train2_1_1_d00000000\n",
      "train2_1_1_d00000000\n",
      "train2_1_1_d00000000\n",
      "train6_1_1_d00000000\n",
      "train6_1_1_d00000000\n",
      "train6_1_1_d00000000\n",
      "train7_5_0_d00000000\n",
      "train7_5_0_d00000000\n",
      "train7_5_0_d00000000\n",
      "train0_2_0_d00000000\n",
      "train0_2_0_d00000000\n",
      "train0_2_0_d00000000\n",
      "train5_2_0_d00000000\n",
      "train5_2_0_d00000000\n",
      "train5_2_0_d00000000\n",
      "train3_1_0_d00000000\n",
      "train3_1_0_d00000000\n",
      "train3_1_0_d00000000\n",
      "train8_2_0_d00000000\n",
      "train8_2_0_d00000000\n",
      "train8_2_0_d00000000\n",
      "train6_2_0_d00000000\n",
      "train6_2_0_d00000000\n",
      "train6_2_0_d00000000\n",
      "train2_1_0_d00000000\n",
      "train2_1_0_d00000000\n",
      "train2_1_0_d00000000\n",
      "train7_1_0_d00000000\n",
      "train7_1_0_d00000000\n",
      "train7_1_0_d00000000\n",
      "train0_1_0_d00000000\n",
      "train0_1_0_d00000000\n",
      "train0_1_0_d00000000\n",
      "train8_1_0__d00000000\n",
      "train8_1_0__d00000000\n",
      "train8_1_0__d00000000\n",
      "train1_1_0_d00000000\n",
      "train1_1_0_d00000000\n",
      "train1_1_0_d00000000\n",
      "train7_1_1_d00000000\n",
      "train7_1_1_d00000000\n",
      "train7_1_1_d00000000\n",
      "train8_1_1_d00000000\n",
      "train8_1_1_d00000000\n",
      "train8_1_1_d00000000\n",
      "train4_1_0_d00000000\n",
      "train4_1_0_d00000000\n",
      "train4_1_0_d00000000\n",
      "train3_1_1_d00000000\n",
      "train3_1_1_d00000000\n",
      "train3_1_1_d00000000\n",
      "train1_4_0_d00000000\n",
      "train1_4_0_d00000000\n",
      "train1_4_0_d00000000\n"
     ]
    }
   ],
   "source": [
    "# frist batch yolo train selection \n",
    "\n",
    "for root,dirs,files in os.walk(\"firstbatch/unzips\"):\n",
    "    dirs = [d for d in dirs if 'obj_train' in d]\n",
    "\n",
    "    for d in dirs:\n",
    "        dirname = root.split('/')[-1]\n",
    "        if not os.path.exists('firstbatch_selected/'+dirname):\n",
    "            os.makedirs('firstbatch_selected/'+dirname)\n",
    "        dstdir = 'firstbatch_selected/'+dirname\n",
    "        otdpath = os.path.join(root,d)\n",
    "        files = os.listdir(otdpath)\n",
    "        txts = [f for f in files if f[-3:]=='txt']\n",
    "        o=0\n",
    "        c=0\n",
    "        obj=0\n",
    "        o_candi = []\n",
    "        c_candi = []\n",
    "        obj_candi = []\n",
    "        for txt in txts:\n",
    "            txtpath = os.path.join(otdpath,txt)\n",
    "            with open(txtpath,'r') as txtfile:\n",
    "                lines = txtfile.readlines()\n",
    "            for l in lines:\n",
    "                if l[0]=='0':\n",
    "                    o+=1\n",
    "                    o_candi.append(txtpath)\n",
    "                if l[0]=='1':\n",
    "                    c+=1\n",
    "                    c_candi.append(txtpath)\n",
    "                if l[0]=='3':\n",
    "                    obj+=1\n",
    "                    obj_candi.append(txtpath)\n",
    "        try:\n",
    "            if 'train' in dirname and 'obj' not in dirname:\n",
    "                print(dirname)\n",
    "                o_samples = random.sample(o_candi,240)\n",
    "            else:\n",
    "                o_samples = random.sample(o_candi,80)\n",
    "        except ValueError:\n",
    "            o_samples = o_candi\n",
    "            \n",
    "        try:\n",
    "            if 'train' in dirname and 'obj' not in dirname:\n",
    "                print(dirname)\n",
    "                c__samples = random.sample(c_candi,240)\n",
    "            else:\n",
    "                c__samples = random.sample(c_candi,80)\n",
    "        except ValueError:\n",
    "            c__samples = c_candi     \n",
    "            \n",
    "        try:\n",
    "            if 'train' in dirname and 'obj' not in dirname:\n",
    "                print(dirname)\n",
    "                obj__samples = random.sample(obj_candi,240)\n",
    "            else:\n",
    "                obj__samples = random.sample(obj_candi,80)\n",
    "            \n",
    "        except ValueError:\n",
    "            obj__samples = obj_candi\n",
    "        \n",
    "#         pngpath = txtpath.split('.')[0]+'.png'\n",
    "        samples = [o_samples,c__samples,obj__samples]\n",
    "        for sample in samples:\n",
    "            for txtpath in sample:\n",
    "                pngpath_src = txtpath.split('.')[0]+'.PNG'\n",
    "                pngpath_dst = dstdir+'/'+dirname+'_'+txtpath.split('/')[-1].split('.')[0]+'.PNG'\n",
    "                txtpath_dst = dstdir+'/'+dirname+'_'+txtpath.split('/')[-1]\n",
    "                line_output = []\n",
    "                with open(txtpath,'r') as label:\n",
    "                    labels = label.readlines()\n",
    "                for line in labels:\n",
    "                    if line[0]!='2' and  line[0]!='4' :\n",
    "                        line_output.append(line)\n",
    "                with open(txtpath_dst, 'w') as f:\n",
    "                    for item in line_output:\n",
    "                        f.write(\"%s\" % item)\n",
    "#                 copyfile(txtpath,txtpath_dst)\n",
    "                copyfile(pngpath_src,pngpath_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for root,dirs,files in os.walk('/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected'):\n",
    "    files = [os.path.join(root,f) for f in files if f[-3:]=='PNG']\n",
    "    file_list += files\n",
    "for root,dirs,files in os.walk('secondbatch/secondbatch_yolo_machine'):\n",
    "    files = [os.path.join(root,f)for f in files if f[-3:]=='PNG']\n",
    "    file_list += files\n",
    "for root,dirs,files in os.walk('firstbatch/firstbatch_selected'):\n",
    "    files = [os.path.join(root,f)for f in files if f[-3:]=='PNG']\n",
    "    file_list += files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72737"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# move 123 together yolo\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/firstbatch/firstbatch_selected/\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        if label == 'd':\n",
    "            label = d.split('_')[1][0]\n",
    "        if label == 'v':\n",
    "            label = d.split('_')[2][0]\n",
    "        if label == 's':\n",
    "            label = d.split('_')[2][0]\n",
    "        if label in ['1','2','3','4','5']:\n",
    "#             print(label)\n",
    "            dirpath = os.path.join(root,d,)\n",
    "            dirfiles = os.listdir(dirpath)\n",
    "            dirfiles_txt = [f for f in dirfiles if f[-3:]=='PNG']\n",
    "    #         print(label)\n",
    "            for f in dirfiles_txt:\n",
    "                f = os.path.join(dirpath,f)\n",
    "                txtfile = f.split('.')[0]+'.txt'\n",
    "\n",
    "                if not os.path.exists('fullset/'+label):\n",
    "                    os.makedirs('fullset/'+label)\n",
    "                pngdst = 'fullset/'+label+'/'+f.split('/')[-1]\n",
    "                txtdst = 'fullset/'+label+'/'+f.split('/')[-1].split('.')[0]+'.txt'\n",
    "                copyfile(f,pngdst)    \n",
    "                copyfile(txtfile,txtdst)\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/secondbatch_yolo_machine\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        if label in ['1','2','3','4','5']:\n",
    "            dirpath = os.path.join(root,d,)\n",
    "            dirfiles = os.listdir(dirpath)\n",
    "            dirfiles_txt = [f for f in dirfiles if f[-3:]=='PNG']\n",
    "    #         print(label)\n",
    "            for f in dirfiles_txt:\n",
    "                f = os.path.join(dirpath,f)\n",
    "                txtfile = f.split('.')[0]+'.txt'\n",
    "\n",
    "                if not os.path.exists('fullset/'+label):\n",
    "                    os.makedirs('fullset/'+label)\n",
    "                pngdst = 'fullset/'+label+'/'+f.split('/')[-1]\n",
    "                txtdst = 'fullset/'+label+'/'+f.split('/')[-1].split('.')[0]+'.txt'\n",
    "                copyfile(f,pngdst)    \n",
    "                copyfile(txtfile,txtdst)\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_ocobj_selected\"):\n",
    "    for d in dirs:\n",
    "        label = d.split('_')[3][0]\n",
    "        if label in ['1','2','3','4','5']:\n",
    "            dirpath = os.path.join(root,d,)\n",
    "            dirfiles = os.listdir(dirpath)\n",
    "            dirfiles_txt = [f for f in dirfiles if f[-3:]=='PNG']\n",
    "    #         print(label)\n",
    "            for f in dirfiles_txt:\n",
    "                f = os.path.join(dirpath,f)\n",
    "                txtfile = f.split('.')[0]+'.txt'\n",
    "\n",
    "                if not os.path.exists('fullset/'+label):\n",
    "                    os.makedirs('fullset/'+label)\n",
    "                pngdst = 'fullset/'+label+'/'+f.split('/')[-1]\n",
    "                txtdst = 'fullset/'+label+'/'+f.split('/')[-1].split('.')[0]+'.txt'\n",
    "                copyfile(f,pngdst)    \n",
    "                copyfile(txtfile,txtdst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_list:\n",
    "    \n",
    "    label = f.split('_')[-9][0]\n",
    "    if 'stitche' in f:\n",
    "        label = f.split('_')[-10][0]\n",
    "\n",
    "    if 'ipy' not in f:\n",
    "        try:\n",
    "            int(label)\n",
    "        except Exception:\n",
    "            label = f.split('_')[-8][0]\n",
    "        txtfile = f.split('.')[0]+'.txt'\n",
    "        \n",
    "        if not os.path.exists('fullset/'+label):\n",
    "            os.makedirs('fullset/'+label)\n",
    "        pngdst = 'fullset/'+label+'/'+f.split('/')[-1]\n",
    "        txtdst = 'fullset/'+label+'/'+f.split('/')[-1].split('.')[0]+'.txt'\n",
    "        copyfile(f,pngdst)    \n",
    "        copyfile(txtfile,txtdst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:52<00:00, 46.55s/it] \n"
     ]
    }
   ],
   "source": [
    "# yolo 123 train test val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "dirs = ['1','2','3','4','5']\n",
    "for d in tqdm(dirs):\n",
    "    \n",
    "    allfile = []\n",
    "    for root,dirs,files in os.walk('fullset/'+d+'/'):\n",
    "\n",
    "        files = [os.path.join(root,file) for file in files if file[-3:]=='txt']\n",
    "        allfile+=files\n",
    "\n",
    "    train,val = train_test_split(allfile,test_size=0.35, random_state=42)\n",
    "    val,test = train_test_split(val,test_size=0.33, random_state=42)\n",
    "\n",
    "    for f in train:\n",
    "        dst = 'pots/labels/train/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "    for f in test:\n",
    "        dst = 'test/labels/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "    for f in val:\n",
    "        dst = 'pots/labels/val/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "\n",
    "    for f in train:\n",
    "        f = f [:-3]+'PNG'\n",
    "        dst = 'pots/images/train/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "    for f in test:\n",
    "        f = f [:-3]+'PNG'\n",
    "\n",
    "        dst = 'test/images/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "    for f in val:\n",
    "        f = f [:-3]+'PNG'\n",
    "\n",
    "        dst = 'pots/images/val/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 45651/45651 [00:11<00:00, 3968.76it/s]\n",
      "100%|██████████| 16469/16469 [00:03<00:00, 4557.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# yolo change label 12345 to 01234\n",
    "for root,_,files in os.walk('pots'):\n",
    "    file = [f for f in files if f[-3:]=='txt']\n",
    "    for f in tqdm(file):\n",
    "        line_output=[]\n",
    "        with open(os.path.join(root,f),'r') as fs:\n",
    "            lines = fs.readlines()\n",
    "        for l in lines:\n",
    "            con = l.split(' ')\n",
    "            label = con[0]\n",
    "            con[0] = str(int(con[0])-1)\n",
    "            line_output.append(\" \".join(con))\n",
    "#         print(line_output)\n",
    "        with open(os.path.join(root,f), 'w') as fdd:\n",
    "            for item in line_output:\n",
    "                fdd.write(\"%s\" % item)\n",
    "        if label not in ['1','2','3','4','5']:\n",
    "            print(label)\n",
    "            print (f)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second batch classification data selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-qacpj5ci/opencv/modules/imgcodecs/src/loadsave.cpp:738: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e3b3e7186eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#                     pngpath_dst = os.path.join(dst,sample)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#                     txtpath_dst = os.path.join(dst,txtname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-qacpj5ci/opencv/modules/imgcodecs/src/loadsave.cpp:738: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/secondbatch/second_batch_individual\"):\n",
    "    dirs = [d for d in dirs if d in ['1','2','3','4','5']]\n",
    "    dirpaths = [os.path.join(root,d) for d in dirs ]\n",
    "#     print(dirpaths)\n",
    "    for dirpath in dirpaths:\n",
    "        cpath = os.path.join(dirpath,'lidopen') \n",
    "        opath = os.path.join(dirpath,'lidclose') \n",
    "        objpath = os.path.join(dirpath,'lidopenwithobj') \n",
    "        folders = [cpath,opath,objpath]\n",
    "        for folder in folders:\n",
    "            picfolder = os.path.join(folder,'picture') \n",
    "            txtfolder = os.path.join(folder,'txt')\n",
    "            pictures = os.listdir(picfolder)\n",
    "            pictures.sort() \n",
    "            res = [list(i) for j, i in groupby(pictures, lambda a: a.split('_')[1])]  \n",
    "            for group in res:\n",
    "                try:\n",
    "                    o_samples = random.sample(group,10)\n",
    "                except ValueError:\n",
    "                    o_samples = group\n",
    "                for sample in o_samples:\n",
    "                    pngpath = os.path.join(picfolder,sample)  \n",
    "                    txtname = sample.split('.')[0]+'.txt'\n",
    "                    txtpath = os.path.join(txtfolder,txtname)  \n",
    "                    with open(txtpath,'r') as label:\n",
    "                        labels = label.readlines()\n",
    "                    for line in labels:\n",
    "                        if line[0]!='2' and  line[0]!='4' :\n",
    "                            dirname = dirpath.split('/')[-1]+'_'+line[0]\n",
    "                            dst = '/home/jy/projects/imgs/dataprepare/secondbatch_classify/pots/'+dirname\n",
    "#                             dst = '/home/jy/projects/imgs/dataprepare/secondbatch_classify/pots/background'\n",
    "                            if not os.path.exists(dst):\n",
    "                                os.makedirs(dst)\n",
    "                            image = cv2.imread(pngpath)\n",
    "                            h,w,_ = image.shape\n",
    "                             \n",
    "                            location = line.split(\" \")[1:]\n",
    "                            location = [float(i) for i in location]\n",
    "                            x1 = int((float(location[0])*w))\n",
    "                            y1 = int((float(location[1])*h))\n",
    "                            xw = int((float(location[2]))*w/2)\n",
    "                            xh = int((float(location[3]))*h/2)\n",
    "                            \n",
    "#                             offset= random.uniform(0, 0.5)\n",
    "#                             x1 = x1 + int(xh*(2 + offset))\n",
    "#                             y1 = y1 + int(xh*(2+offset))\n",
    "                            \n",
    "                            crop_img = image[y1-xh:y1+xh, x1-xw:x1+xw]\n",
    "#                             if len(crop_img)==0:\n",
    "#                                 continue\n",
    "                            pngname_dst = pngpath.split('/')[-1]\n",
    "                            imname = dst+'/'+'_'.join(pngname_dst.split('_')[:-2])+ '_'+dirname+'_'+'_'.join(pngname_dst.split('_')[-2:])\n",
    "#                             print(imname)\n",
    "                            if not os.path.isdir(dst):\n",
    "                                os.makedirs(dst)\n",
    "                            cv2.imwrite(imname, crop_img)\n",
    "#                     pngpath_dst = os.path.join(dst,sample)  \n",
    "#                     txtpath_dst = os.path.join(dst,txtname)  \n",
    "#                     line_output=[]\n",
    "\n",
    "#                     with open(txtpath_dst, 'w') as f:\n",
    "#                         for item in line_output:\n",
    "#                             f.write(\"%s\" % item)\n",
    "#                     copyfile(pngpath,pngpath_dst)\n",
    "# #                     copyfile(txtpath,txtpath_dst)\n",
    "         \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thirdbatch machine classifiy data extract\n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/thirdbatch/thirdbatch_unzip/\"):\n",
    "    dirs = [d for d in dirs if 'obj_train' in d]\n",
    "\n",
    "    for d in dirs:\n",
    "        label = os.path.join(root,d).split('/')[-2] .split('_')[3][0]\n",
    "        if label in ['1','2','3','4','5']:\n",
    "\n",
    "            otdpath = os.path.join(root,d)\n",
    "            files = os.listdir(otdpath)\n",
    "            txts = [f for f in files if f[-3:]=='txt']\n",
    "            o=0\n",
    "            c=0\n",
    "            obj=0\n",
    "            o_candi = []\n",
    "            c_candi = []\n",
    "            obj_candi = []\n",
    "            for txt in txts:\n",
    "                txtpath = os.path.join(otdpath,txt)\n",
    "                with open(txtpath,'r') as txtfile:\n",
    "                    lines = txtfile.readlines()\n",
    "                for l in lines:\n",
    "                    if l[0]=='0':\n",
    "                        o+=1\n",
    "                        o_candi.append(txtpath)\n",
    "                    if l[0]=='1':\n",
    "                        c+=1\n",
    "                        c_candi.append(txtpath)\n",
    "                    if l[0]=='3':\n",
    "                        obj+=1\n",
    "                        obj_candi.append(txtpath)\n",
    "            try:\n",
    "                o_samples = random.sample(o_candi,80)\n",
    "            except ValueError:\n",
    "                o_samples = o_candi\n",
    "\n",
    "            try:\n",
    "                c__samples = random.sample(c_candi,80)\n",
    "            except ValueError:\n",
    "                c__samples = c_candi     \n",
    "\n",
    "            try:\n",
    "                obj__samples = random.sample(obj_candi,80)\n",
    "\n",
    "            except ValueError:\n",
    "                obj__samples = obj_candi\n",
    "\n",
    "    #         pngpath = txtpath.split('.')[0]+'.png'\n",
    "            samples = [o_samples,c__samples,obj__samples]\n",
    "            \n",
    "\n",
    "            for sample in samples:\n",
    "                for txtpath in sample:\n",
    "                    \n",
    "                    line_output = []\n",
    "                    with open(txtpath,'r') as labeltxt:\n",
    "                        labels = labeltxt.readlines()\n",
    "                    for line in labels:\n",
    "                        if line[0]!='2' and  line[0]!='4' :\n",
    "                            dirname = label+'_'+line[0]\n",
    "\n",
    "                            if not os.path.exists('/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/background'):\n",
    "                                os.makedirs('/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/background')\n",
    "                            dstdir = '/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/background'\n",
    "#                             if not os.path.exists('/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/'+dirname+'_background'):\n",
    "#                                 os.makedirs('/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/'+dirname)\n",
    "#                             dstdir = '/home/jy/projects/imgs/dataprepare/thirdbatch_classify/pots/'+dirname\n",
    "                            \n",
    "                            pngpath = txtpath[0:-3]+'PNG'\n",
    "                            image = cv2.imread(pngpath)\n",
    "                            h,w,_ = image.shape\n",
    "                             \n",
    "                                \n",
    "                            location = line.split(\" \")[1:]\n",
    "                            location = [float(i) for i in location]\n",
    "                            \n",
    "                             \n",
    "                            \n",
    "                            \n",
    "                            x1 = int((float(location[0])*w))\n",
    "                            y1 = int((float(location[1])*h))\n",
    "                            xw = int((float(location[2]))*w/2)\n",
    "                            xh = int((float(location[3]))*h/2)\n",
    "#                             offset= random.uniform(0, 0.5)\n",
    "#                             x1 = x1 + int(xh*(2 + offset))\n",
    "#                             y1 = y1 + int(xh*(2+offset))\n",
    "                            crop_img = image[y1-xh:y1+xh, x1-xw:x1+xw]\n",
    "                            \n",
    "            \n",
    "                            pngname_dst = pngpath.split('/')[-1]\n",
    "                            imname = dstdir+'/'+os.path.join(root,d).split('/')[-2]+ '_'+dirname+'_'+'_'.join(pngname_dst.split('_')[-2:])\n",
    "#                             print(imname)\n",
    "#                             if not os.path.isdir(dst):\n",
    "#                                 os.makedirs(dst)\n",
    "                            cv2.imwrite(imname, crop_img)\n",
    "\n",
    "    #                 copyfile(txtpath,txtpath_dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 116, 3), dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/1_0\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/4_0\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/2_0\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/5_0\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/3_1\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/5_3\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/2_1\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/5_1\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/4_3\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/2_3\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/3_3\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/1_1\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/4_1\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/1_3\n",
      "/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots/3_0\n"
     ]
    }
   ],
   "source": [
    "# first batch machine dataset extract \n",
    "for root,dirs,files in os.walk(\"/home/jy/projects/imgs/dataprepare/firstbatch_classify/pots\"):\n",
    "    dirs = [d for d in dirs if d.split('_')[0] in ['1','2','3','4','5']]\n",
    "    dirpaths = [os.path.join(root,d) for d in dirs ]\n",
    "    for dirpath in dirpaths:\n",
    "        print(dirpath)\n",
    "        nontrain = []\n",
    "        \n",
    "        for rootx,dirsx,filesx in os.walk(dirpath):\n",
    "            for f in filesx:\n",
    "                nontrain.append(f)\n",
    "            nontrain.sort() \n",
    "            res = [list(i) for j, i in groupby(nontrain, lambda a: '_'.join(a.split('_')[-5:-1]))]  \n",
    "\n",
    "        #     for dirpath in dirpaths:\n",
    "\n",
    "            for group in res:\n",
    "                candi = []\n",
    "                for image in group:\n",
    "\n",
    "                    if 'train' not in image:\n",
    "\n",
    "                        candi.append(image)\n",
    "\n",
    "                try:\n",
    "                    o_samples = random.sample(candi,80)\n",
    "                except ValueError:\n",
    "                    o_samples = candi\n",
    "                for oss in o_samples:\n",
    "                    dirpath_dst = dirpath.replace('pots', 'pots_selected')\n",
    "                    if not os.path.exists(dirpath_dst):\n",
    "                        os.makedirs(dirpath_dst)\n",
    "                    copyfile(os.path.join(dirpath,oss),os.path.join(dirpath_dst,oss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 71/1564 [00:00<00:02, 708.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/1_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1564/1564 [00:02<00:00, 770.87it/s]\n",
      "100%|██████████| 1564/1564 [00:01<00:00, 782.87it/s]\n",
      " 35%|███▌      | 171/482 [00:00<00:00, 1699.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/4_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:00<00:00, 1531.86it/s]\n",
      "100%|██████████| 482/482 [00:00<00:00, 1482.26it/s]\n",
      " 11%|█         | 91/812 [00:00<00:00, 906.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/2_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 812/812 [00:01<00:00, 786.96it/s]\n",
      "100%|██████████| 812/812 [00:00<00:00, 871.83it/s]\n",
      " 12%|█▏        | 113/918 [00:00<00:00, 1097.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/5_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [00:00<00:00, 1159.30it/s]\n",
      "100%|██████████| 918/918 [00:00<00:00, 933.78it/s] \n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  5%|▌         | 55/1014 [00:00<00:01, 547.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/5_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [00:01<00:00, 824.42it/s]\n",
      "100%|██████████| 1014/1014 [00:01<00:00, 780.53it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      " 34%|███▎      | 115/343 [00:00<00:00, 1148.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/4_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:00<00:00, 1209.83it/s]\n",
      "100%|██████████| 343/343 [00:00<00:00, 921.71it/s]\n",
      "  7%|▋         | 57/804 [00:00<00:01, 567.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/2_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [00:00<00:00, 847.32it/s]\n",
      "100%|██████████| 804/804 [00:01<00:00, 654.09it/s]\n",
      "  8%|▊         | 99/1214 [00:00<00:01, 984.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/3_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1214/1214 [00:01<00:00, 1152.13it/s]\n",
      "100%|██████████| 1214/1214 [00:01<00:00, 1043.78it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  4%|▎         | 66/1822 [00:00<00:02, 649.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/1_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1822/1822 [00:02<00:00, 731.34it/s]\n",
      "100%|██████████| 1822/1822 [00:02<00:00, 720.33it/s]\n",
      " 17%|█▋        | 155/934 [00:00<00:00, 1542.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pots_classicifation_123batch/3_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 934/934 [00:00<00:00, 1563.72it/s]\n",
      "100%|██████████| 934/934 [00:00<00:00, 1296.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# machine classification augmentation \n",
    "transform_flip = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "transform_rotate = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "transform_ShiftScaleRotate = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=90, p=1),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "alies_transform = ['flip','rotate']\n",
    "\n",
    "for root,dirs,files in os.walk(\"pots_classicifation_123batch\"):\n",
    "    \n",
    "    for d in dirs:\n",
    "        allfile = []\n",
    "        flag = d.split('_')[1]\n",
    "        if flag =='0' or flag=='3':\n",
    "            print((os.path.join(root,d)))\n",
    "            for rootx,dirsx,filesx in os.walk(os.path.join(root,d)):\n",
    "                files = [os.path.join(root,d,f) for f in filesx if f[-3:]=='PNG']\n",
    "                allfile+=files\n",
    "#     for f in files:\n",
    "# #         if len(f)<140:\n",
    "#             print(f)\n",
    "    \n",
    "        sample_num = round(len(allfile)*0.5)\n",
    "        flipfiles = random.sample(allfile,sample_num)\n",
    "        rotatefiles = random.sample(allfile,sample_num)\n",
    "        filelist = [flipfiles,rotatefiles]\n",
    "\n",
    "        transforms = [transform_flip,transform_rotate]\n",
    "\n",
    "        for idx,file in enumerate( filelist):\n",
    "            for f in tqdm( file):\n",
    "\n",
    "                pngpath =  f [:-3]+'PNG'\n",
    "                image = cv2.imread(pngpath)\n",
    "\n",
    "                transform = transforms[idx]\n",
    "                try:\n",
    "                    transformed = transform(image=image)\n",
    "                except :\n",
    "                    continue\n",
    "                transformed_image = transformed['image']\n",
    "\n",
    "        #         print(transformed_class_labels)\n",
    "        #         print(transformed_bboxes)\n",
    "\n",
    "\n",
    "\n",
    "                save_prefix = str(alies_transform[idx])\n",
    "                save_path = '/'.join(pngpath.split(\"/\")[:-1])\n",
    "                png_save_path = save_path+'/'+save_prefix+'_'+pngpath.split(\"/\")[-1]\n",
    "\n",
    "                cv2.imwrite(png_save_path,transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# train test val split classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dirs = os.listdir('pots_classicifation_123batch')\n",
    "\n",
    "for d in tqdm(dirs):\n",
    "    \n",
    "    allfile = []\n",
    "    for root,dirs,files in os.walk('pots_classicifation_123batch/'+d+'/'):\n",
    "\n",
    "        files = [os.path.join(root,file) for file in files if file[-3:]=='PNG']\n",
    "        allfile+=files\n",
    "\n",
    "    train,val = train_test_split(allfile,test_size=0.35, random_state=42)\n",
    "#     val,test = train_test_split(val,test_size=0.33, random_state=42)\n",
    " \n",
    "\n",
    "    for f in train:\n",
    "        f = f [:-3]+'PNG'\n",
    "        dst = 'pots_classicifation_123batch_traintestval/train/'+d+'/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)\n",
    "#     for f in test:\n",
    "#         f = f [:-3]+'PNG'\n",
    "\n",
    "#         dst = 'pots_classicifation_123batch_traintestval/test/'\n",
    "#         if not os.path.isdir(dst):\n",
    "#             os.makedirs(dst)\n",
    "#         dst_file = dst+f.split('/')[-1]\n",
    "#         copyfile(f,dst_file)\n",
    "    for f in val:\n",
    "        f = f [:-3]+'PNG'\n",
    "\n",
    "        dst = 'pots_classicifation_123batch_traintestval/val/'+d+'/'\n",
    "        if not os.path.isdir(dst):\n",
    "            os.makedirs(dst)\n",
    "        dst_file = dst+f.split('/')[-1]\n",
    "        copyfile(f,dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-68e8f8c4c9eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvidname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'videos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'videos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                 if (\n\u001b[1;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 129/416 [00:57<03:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.5.1) /tmp/pip-req-build-1syr35c1/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [13:01<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk('/media/jy/SUMSUNGSSD/videosultra'):\n",
    "    for d in tqdm(dirs):\n",
    "        dirpath = os.path.join(root,d)\n",
    "        videospath = os.listdir(dirpath)\n",
    "        videospath = [os.path.join(root,d,v) for v in videospath if v[-3:]=='mp4']\n",
    "        labelpath = os.path.join(dirpath,'labels')\n",
    "        labelpath = os.path.join(labelpath,os.listdir(labelpath)[0])\n",
    "        with open(labelpath,'r') as labeltxt:\n",
    "            locations = labeltxt.readlines()\n",
    "        for location in locations:\n",
    "            location = location.rstrip()\n",
    "            location = location.split(' ')\n",
    "            label = location[0]\n",
    "            x1 = float(location[1])\n",
    "            y1 = float(location[2])\n",
    "            x2 = float(location[3])\n",
    "            y2 = float(location[4])\n",
    "\n",
    "        for vid in videospath:\n",
    "            dirname = vid.split('/')[-2]\n",
    "            filename = vid.split('/')[-1]\n",
    "            newdir = os.path.join('/media/jy/SUMSUNGSSD/videosultra_1/',dirname)\n",
    "            if os.path.exists(newdir):\n",
    "                continue\n",
    "            vcap = cv2.VideoCapture(vid)\n",
    "            \n",
    "            frame_counter = 0\n",
    "            fps = int(vcap.get(cv2.CAP_PROP_FPS))\n",
    "            last_frame=[]\n",
    "            mse_count = 0\n",
    "            last_counter = 0\n",
    "            moving_avg = []\n",
    "            moving_light = []\n",
    "            success = True\n",
    "            while success:\n",
    "                try:\n",
    "                    if frame_counter % (1 * fps) == 0:\n",
    "                        success, current_frame = vcap.read()\n",
    "                        frame_counter_in_seconds = int(frame_counter / fps)\n",
    "                        # if no current_frame captured\n",
    "                        if current_frame is None:\n",
    "                            continue\n",
    "                        h, w, _ = current_frame.shape\n",
    "                        x1r = int(x1 * w)\n",
    "                        y1r = int(y1 * h)\n",
    "                        x2r = int(x2 * w)\n",
    "                        y2r = int(y2 * h)\n",
    "\n",
    "                        obj_crop_image = current_frame[y1r:y2r, x1r:x2r]\n",
    "                        obj_crop_image = cv2.GaussianBlur(obj_crop_image, (15, 15), 0)\n",
    "                        found = False\n",
    "                        if len(last_frame) > 0:\n",
    "                            obj_crop_image_last_frame = last_frame[y1r:y2r, x1r:x2r]\n",
    "                            obj_crop_image_last_frame = cv2.GaussianBlur(obj_crop_image_last_frame, (15, 15), 0)\n",
    "                            try:\n",
    "                                mse_value = mse(obj_crop_image_last_frame, obj_crop_image)\n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                break\n",
    "                            moving_avg.append(mse_value)\n",
    "                            if mse_value > 200 :\n",
    "                                mse_count+=1\n",
    "                            last_counter = frame_counter_in_seconds\n",
    "\n",
    "\n",
    "\n",
    "    #                             print(moving_avg)\n",
    "    #                             print(moving_average(moving_avg, 10))\n",
    "\n",
    "\n",
    "                            b, g, r = cv2.split(obj_crop_image)\n",
    "                            r_g = np.count_nonzero(abs(r - g))\n",
    "                            r_b = np.count_nonzero(abs(r - b))\n",
    "                            g_b = np.count_nonzero(abs(g - b))\n",
    "                            diff_sum = float(r_g + r_b + g_b)\n",
    "\n",
    "                            ### finding ratio of diff_sum with respect to size of image\n",
    "                            ratio = diff_sum / obj_crop_image.size\n",
    "                            # print(ratio)\n",
    "\n",
    "                            avg = np.mean(obj_crop_image)\n",
    "                            moving_light.append(avg)\n",
    "\n",
    "                            if len(moving_light) > 5:\n",
    "                                diff = (moving_light[-1] - moving_light[-2]) / moving_light[-2]\n",
    "                                if diff>0.31 or diff<-0.31 or ratio <0.5:\n",
    "\n",
    "                                    found = False \n",
    "\n",
    "                                    moving_avg = []\n",
    "\n",
    "                            if len(moving_avg)>0 and moving_average(moving_avg, 10)[-1]>1000:\n",
    "                                found = True\n",
    "                        if found:\n",
    "\n",
    "\n",
    "                            try:\n",
    "                                os.makedirs(newdir)\n",
    "                            except FileExistsError:\n",
    "                                pass\n",
    "                            copyfile(vid,os.path.join(newdir,filename))\n",
    "                            break\n",
    "                        last_frame = current_frame\n",
    "                    else:\n",
    "                        success = vcap.grab()\n",
    "                    frame_counter+=1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a, b):\n",
    "    \"\"\"\n",
    "    calculate mse between image a and b\n",
    "    :param a: image\n",
    "    :param b: image\n",
    "    :return: mse\n",
    "    \"\"\"\n",
    "    err = np.sum((a.astype(\"float\") - b.astype(\"float\")) ** 2)\n",
    "    err /= float(a.shape[0] * a.shape[0])\n",
    "\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D81141170_2021_01_20_00_39_16.mp4',\n",
       " 'D81141170_2021_01_20_02_52_01.mp4',\n",
       " 'D81141170_2021_01_21_02_16_26.mp4',\n",
       " 'D81141170_2021_01_20_00_27_16.mp4',\n",
       " 'D81141170_2021_01_20_00_57_17.mp4',\n",
       " 'D81141170_2021_01_22_07_06_30.mp4',\n",
       " 'D81141170_2021_01_20_00_51_16.mp4',\n",
       " 'D81141170_2021_01_20_01_10_03.mp4',\n",
       " 'D81141170_2021_01_24_05_07_47.mp4',\n",
       " 'D81141170_2021_01_22_07_18_30.mp4',\n",
       " 'D81141170_2021_01_24_05_01_51.mp4',\n",
       " 'D81141170_2021_01_23_11_00_40.mp4',\n",
       " 'D81141170_2021_01_24_04_19_30.mp4',\n",
       " 'D81141170_2021_01_24_04_22_31.mp4',\n",
       " 'D81141170_2021_01_22_06_36_29.mp4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videospath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
